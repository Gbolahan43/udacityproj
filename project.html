<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>9f0821caa43541a38aced3f1b4223a64</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="predict-bike-sharing-demand-with-autogluon-template"
class="cell markdown" id="snVTjmhZI2wv">
<h1>Predict Bike Sharing Demand with AutoGluon Template</h1>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="paMUof76oeD6" data-outputId="afe1538e-4d95-4119-e0e6-8437ca27b533">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">&#39;/content/drive&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mounted at /content/drive
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="1"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="9h5OjG4MrcVY" data-outputId="1f28503d-62cc-492d-a2ee-707f7b097a07">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls</span></code></pre></div>
<div class="output stream stdout">
<pre><code>sample_data
</code></pre>
</div>
</div>
<section id="project-predict-bike-sharing-demand-with-autogluon"
class="cell markdown" id="TCwe6fauI2wz">
<h2>Project: Predict Bike Sharing Demand with AutoGluon</h2>
<p>This notebook is a template with each step that you need to complete
for the project.</p>
<p>Please fill in your code where there are explicit <code>?</code>
markers in the notebook. You are welcome to add more cells and code as
you see fit.</p>
<p>Once you have completed all the code implementations, please export
your notebook as a HTML file so the reviews can view your code. Make
sure you have all outputs correctly outputted.</p>
<p><code>File-&gt; Export Notebook As... -&gt; Export Notebook as HTML</code></p>
<p>There is a writeup to complete as well after all code implememtation
is done. Please answer all questions and attach the necessary tables and
charts. You can complete the writeup in either markdown or PDF.</p>
<p>Completing the code template and writeup template will cover all of
the rubric points for this project.</p>
<p>The rubric contains "Stand Out Suggestions" for enhancing the project
beyond the minimum requirements. The stand out suggestions are optional.
If you decide to pursue the "stand out suggestions", you can include the
code in this notebook and also discuss the results in the writeup
file.</p>
</section>
<section id="step-1-create-an-account-with-kaggle" class="cell markdown"
id="ssJUFutYI2w1">
<h2>Step 1: Create an account with Kaggle</h2>
</section>
<section id="create-kaggle-account-and-download-api-key"
class="cell markdown" id="6diwA7XPI2w3">
<h3>Create Kaggle Account and download API key</h3>
<p>Below is example of steps to get the API username and key. Each
student will have their own username and key.</p>
</section>
<div class="cell markdown" id="8o5rpBySI2w4">
<ol>
<li><p>Open account settings.</p></li>
<li><p>Scroll down to API and click Create New API Token.</p></li>
<li><p>Open up <code>kaggle.json</code> and use the username and
key.</p></li>
</ol>
</div>
<section
id="step-2-download-the-kaggle-dataset-using-the-kaggle-python-library"
class="cell markdown" id="HtB12PXUI2w5">
<h2>Step 2: Download the Kaggle dataset using the kaggle python
library</h2>
</section>
<section id="open-up-sagemaker-studio-and-use-starter-template"
class="cell markdown" id="PVoea0NMI2w5">
<h3>Open up Sagemaker Studio and use starter template</h3>
</section>
<div class="cell markdown" id="wUDpwFu_I2w6">
<ol>
<li>Notebook should be using a <code>ml.t3.medium</code> instance (2
vCPU + 4 GiB)</li>
<li>Notebook should be using kernal:
<code>Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)</code></li>
</ol>
</div>
<section id="install-packages" class="cell markdown" id="0K9Km0QcI2w6">
<h3>Install packages</h3>
</section>
<div class="cell code" data-execution_count="2"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="MC2hCHvvI2w7" data-outputId="55ae2bb3-9413-491b-dd65-5c15d6594d90">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U pip</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U setuptools wheel</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U <span class="st">&quot;mxnet&lt;2.0.0&quot;</span> bokeh<span class="op">==</span><span class="fl">2.0.1</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install autogluon <span class="op">--</span>no<span class="op">-</span>cache<span class="op">-</span><span class="bu">dir</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Without --no-cache-dir, smaller aws instances may have trouble installing</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)
Collecting setuptools
  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 26.8 MB/s eta 0:00:00
ent already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)
Installing collected packages: setuptools
  Attempting uninstall: setuptools
    Found existing installation: setuptools 67.7.2
    Uninstalling setuptools-67.7.2:
      Successfully uninstalled setuptools-67.7.2
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
ipython 7.34.0 requires jedi&gt;=0.16, which is not installed.
Successfully installed setuptools-67.8.0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb7"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;pip_warning&quot;</span><span class="fu">:{</span><span class="dt">&quot;packages&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="st">&quot;_distutils_hack&quot;</span><span class="ot">,</span><span class="st">&quot;pkg_resources&quot;</span><span class="ot">,</span><span class="st">&quot;setuptools&quot;</span><span class="ot">]</span><span class="fu">}}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting mxnet&lt;2.0.0
  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 MB 17.2 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 107.4 MB/s eta 0:00:00
etadata (setup.py) ... ent already satisfied: PyYAML&gt;=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (2.8.2)
Requirement already satisfied: Jinja2&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (3.1.2)
Requirement already satisfied: numpy&gt;=1.11.3 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (1.22.4)
Requirement already satisfied: pillow&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (8.4.0)
Requirement already satisfied: packaging&gt;=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (23.1)
Requirement already satisfied: tornado&gt;=5 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.3.1)
Requirement already satisfied: typing_extensions&gt;=3.7.4 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (4.5.0)
Requirement already satisfied: requests&lt;3,&gt;=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet&lt;2.0.0) (2.27.1)
Collecting graphviz&lt;0.9.0,&gt;=0.8.1 (from mxnet&lt;2.0.0)
  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2&gt;=2.7-&gt;bokeh==2.0.1) (2.1.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.1-&gt;bokeh==2.0.1) (1.16.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (3.4)
Building wheels for collected packages: bokeh
  Building wheel for bokeh (setup.py) ... e=bokeh-2.0.1-py3-none-any.whl size=9080019 sha256=4681230566a1b64cd93daf176421f799b1d182a04f37be7dd072cedc56ff830d
  Stored in directory: /root/.cache/pip/wheels/be/b4/d8/7ce778fd6e637bea03a561223a77ba6649aff8168e3c613754
Successfully built bokeh
Installing collected packages: graphviz, mxnet, bokeh
  Attempting uninstall: graphviz
    Found existing installation: graphviz 0.20.1
    Uninstalling graphviz-0.20.1:
      Successfully uninstalled graphviz-0.20.1
  Attempting uninstall: bokeh
    Found existing installation: bokeh 2.4.3
    Uninstalling bokeh-2.4.3:
      Successfully uninstalled bokeh-2.4.3
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
Successfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.1
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting autogluon
  Downloading autogluon-0.7.0-py3-none-any.whl (9.7 kB)
Collecting autogluon.core[all]==0.7.0 (from autogluon)
  Downloading autogluon.core-0.7.0-py3-none-any.whl (218 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 218.3/218.3 kB 11.9 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.features-0.7.0-py3-none-any.whl (60 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.1/60.1 kB 153.3 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.tabular-0.7.0-py3-none-any.whl (292 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 292.2/292.2 kB 178.5 MB/s eta 0:00:00
ultimodal==0.7.0 (from autogluon)
  Downloading autogluon.multimodal-0.7.0-py3-none-any.whl (331 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 331.1/331.1 kB 297.7 MB/s eta 0:00:00
eseries[all]==0.7.0 (from autogluon)
  Downloading autogluon.timeseries-0.7.0-py3-none-any.whl (108 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 108.7/108.7 kB 239.2 MB/s eta 0:00:00
ent already satisfied: numpy&lt;1.27,&gt;=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.22.4)
Requirement already satisfied: scipy&lt;1.12,&gt;=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.10.1)
Requirement already satisfied: scikit-learn&lt;1.3,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.2.2)
Collecting networkx&lt;3.0,&gt;=2.3 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 163.9 MB/s eta 0:00:00
ent already satisfied: pandas&lt;1.6,&gt;=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.5.3)
Requirement already satisfied: tqdm&lt;5,&gt;=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (4.65.0)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (2.27.1)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (3.7.1)
Collecting boto3&lt;2,&gt;=1.10 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading boto3-1.26.151-py3-none-any.whl (135 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 293.8 MB/s eta 0:00:00
mon==0.7.0 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading autogluon.common-0.7.0-py3-none-any.whl (45 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.0/45.0 kB 203.6 MB/s eta 0:00:00
ent already satisfied: hyperopt&lt;0.2.8,&gt;=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (0.2.7)
Collecting ray[tune]&lt;2.3,&gt;=2.2 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.4/57.4 MB 114.8 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 329.8 MB/s eta 0:00:00
a&lt;4.18,&gt;=4.14 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 274.0 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading seqeval-1.2.2.tar.gz (43 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 209.3 MB/s eta 0:00:00
etadata (setup.py) ...  autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 254.2 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.7/199.7 kB 265.5 MB/s eta 0:00:00
m&lt;0.7.0,&gt;=0.6.12 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading timm-0.6.13-py3-none-any.whl (549 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 549.1/549.1 kB 343.2 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.5/887.5 MB 162.5 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.2/24.2 MB 122.5 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading fairscale-0.4.13.tar.gz (266 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.3/266.3 kB 317.5 MB/s eta 0:00:00
ents to build wheel ... etadata (pyproject.toml) ... ent already satisfied: scikit-image&lt;0.20.0,&gt;=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Collecting pytorch-lightning&lt;1.10.0,&gt;=1.9.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 829.5/829.5 kB 311.1 MB/s eta 0:00:00
ent already satisfied: text-unidecode&lt;1.4,&gt;=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.3)
Collecting torchmetrics&lt;0.9.0,&gt;=0.8.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 320.7 MB/s eta 0:00:00
ers&lt;4.27.0,&gt;=4.23.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 134.5 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)
Collecting omegaconf&lt;2.3.0,&gt;=2.1.1 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.3/79.3 kB 270.8 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 351.6 MB/s eta 0:00:00
etric-learning&lt;2.0,&gt;=1.3.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.2/112.2 kB 252.2 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.5/410.5 kB 180.1 MB/s eta 0:00:00
ent already satisfied: nltk&lt;4.0.0,&gt;=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.8.1)
Collecting openmim&lt;0.4.0,&gt;0.1.5 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.3/51.3 kB 176.5 MB/s eta 0:00:00
ent already satisfied: defusedxml&lt;0.7.2,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.1)
Requirement already satisfied: jinja2&lt;3.2,&gt;=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.1.2)
Requirement already satisfied: tensorboard&lt;3,&gt;=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (2.12.2)
Collecting pytesseract&lt;0.3.11,&gt;=0.3.9 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)
Collecting catboost&lt;1.2,&gt;=1.0 (from autogluon.tabular[all]==0.7.0-&gt;autogluon)
  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.6/76.6 MB 139.1 MB/s eta 0:00:00
ent already satisfied: lightgbm&lt;3.4,&gt;=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.5)
Requirement already satisfied: xgboost&lt;1.8,&gt;=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.7.5)
Requirement already satisfied: fastai&lt;2.8,&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.7.12)
Requirement already satisfied: joblib&lt;2,&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.2.0)
Requirement already satisfied: statsmodels&lt;0.14,&gt;=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.13.5)
Collecting gluonts&lt;0.13,&gt;=0.12.0 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading gluonts-0.12.8-py3-none-any.whl (1.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 304.2 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 234.6 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading ujson-5.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 172.6 MB/s eta 0:00:00
e&lt;0.16,&gt;=0.14 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading sktime-0.15.1-py3-none-any.whl (16.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 166.9 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.0/44.0 kB 194.6 MB/s eta 0:00:00
darima&lt;1.9,&gt;=1.8.2 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading pmdarima-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 166.7 MB/s eta 0:00:00
ent already satisfied: psutil&lt;6,&gt;=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (5.9.5)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (67.8.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (6.0)
Collecting botocore&lt;1.30.0,&gt;=1.29.151 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading botocore-1.29.151-py3-none-any.whl (10.9 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 200.1 MB/s eta 0:00:00
espath&lt;2.0.0,&gt;=0.7.1 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Collecting s3transfer&lt;0.7.0,&gt;=0.6.0 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 174.9 MB/s eta 0:00:00
ent already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.8.4)
Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (5.13.1)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.16.0)
Collecting datasets&gt;=2.0.0 (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 200.7 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading dill-0.3.6-py3-none-any.whl (110 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 179.6 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.5/212.5 kB 191.0 MB/s eta 0:00:00
ultiprocess (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.3/134.3 kB 174.5 MB/s eta 0:00:00
ent already satisfied: fsspec[http]&gt;=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.0)
Collecting huggingface-hub&gt;=0.7.0 (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 236.8/236.8 kB 195.4 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading responses-0.18.0-py3-none-any.whl (38 kB)
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (23.1.2)
Requirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.7)
Requirement already satisfied: fastcore&lt;1.6,&gt;=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.5.29)
Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.3)
Requirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.5.2)
Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.10.7)
Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.12.0)
Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (4.5.0)
Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.18.3)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.2.1)
Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.10.9.7)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2&lt;3.2,&gt;=3.0.3-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.1.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm&lt;3.4,&gt;=3.3-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.40.0)
Requirement already satisfied: gdown&gt;=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.6.6)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (8.1.3)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2022.10.31)
Collecting antlr4-python3-runtime==4.9.* (from omegaconf&lt;2.3.0,&gt;=2.1.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 285.5 MB/s eta 0:00:00
etadata (setup.py) ... a (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Collecting model-index (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)
Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (13.3.4)
Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.8.10)
Requirement already satisfied: python-dateutil&gt;=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.7.1)
Requirement already satisfied: Cython!=0.29.18,&gt;=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.29.34)
Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.26.15)
Collecting lightning-utilities&gt;=0.6.0.post0 (from pytorch-lightning&lt;1.10.0,&gt;=1.9.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.12.0)
Requirement already satisfied: msgpack&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.5)
Requirement already satisfied: protobuf!=3.19.5,&gt;=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.20.3)
Collecting aiosignal (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Collecting frozenlist (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 184.2 MB/s eta 0:00:00
 ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 186.1 MB/s eta 0:00:00
ent already satisfied: grpcio&gt;=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.54.0)
Collecting tensorboardX&gt;=1.9 (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 238.4 MB/s eta 0:00:00
ent already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.4)
Requirement already satisfied: imageio&gt;=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.25.1)
Requirement already satisfied: tifffile&gt;=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.12)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.1)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&lt;1.3,&gt;=1.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.1.0)
Collecting deprecated&gt;=1.2.13 (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)
Requirement already satisfied: numba&gt;=0.55 in /usr/local/lib/python3.10/dist-packages (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.56.4)
Requirement already satisfied: patsy&gt;=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels&lt;0.14,&gt;=0.13.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.5.3)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.0)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.4.3)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.8.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.3.0)
Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 280.7 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 143.7 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 53.4 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 79.9 MB/s eta 0:00:00
 torchmetrics&lt;0.9.0,&gt;=0.8.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)
Collecting tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 (from transformers&lt;4.27.0,&gt;=4.23.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 247.4 MB/s eta 0:00:00
ent already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.0.9)
Requirement already satisfied: pyarrow&gt;=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (9.0.0)
Collecting aiohttp (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 297.5 MB/s eta 0:00:00
ent already satisfied: wrapt&lt;2,&gt;=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated&gt;=1.2.13-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.14.1)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.11.2)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (5.3.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.3.1)
Requirement already satisfied: llvmlite&lt;0.40,&gt;=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba&gt;=0.55-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.39.1)
Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.12)
Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.4)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.9)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.7)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.8)
Requirement already satisfied: thinc&lt;8.2.0,&gt;=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.1.9)
Requirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.1.1)
Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.4.6)
Requirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.8)
Requirement already satisfied: typer&lt;0.8.0,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: pathy&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.10.1)
Requirement already satisfied: smart-open&lt;7.0.0,&gt;=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (6.3.0)
Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.0)
Collecting distlib&lt;1,&gt;=0.3.6 (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.5/468.5 kB 313.8 MB/s eta 0:00:00
ent already satisfied: platformdirs&lt;4,&gt;=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.3.0)
Collecting ordered-set (from model-index-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)
Requirement already satisfied: tenacity&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly-&gt;catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.2.2)
Requirement already satisfied: markdown-it-py&lt;3.0.0,&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.2.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.14.0)
Collecting multidict&lt;7.0,&gt;=4.5 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 184.5 MB/s eta 0:00:00
eout&lt;5.0,&gt;=4.0.0a3 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting yarl&lt;2.0,&gt;=1.0 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 197.0 MB/s eta 0:00:00
ent already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&lt;3.0.0,&gt;=2.2.0-&gt;rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.2)
Requirement already satisfied: pyasn1&lt;0.6.0,&gt;=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.2.2)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.9)
Requirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.4)
Requirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-&gt;gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.4.1)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.7.1)
Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval
  Building wheel for fairscale (pyproject.toml) ... e=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=f30b73117417377c198f7b638b76cfa41669aec130585860ab7edc767aba475a
  Stored in directory: /tmp/pip-ephem-wheel-cache-8y7pz6ss/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3
  Building wheel for antlr4-python3-runtime (setup.py) ... e: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=26eab5b93d2aeeb58484fb85997cf03e14a780c0336a16d625a7e628d63b4a3f
  Stored in directory: /tmp/pip-ephem-wheel-cache-8y7pz6ss/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88
  Building wheel for seqeval (setup.py) ... e=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=fc670819b5d0de61cfe02389553d9b561679d76635b8de80d32b181923a39ee8
  Stored in directory: /tmp/pip-ephem-wheel-cache-8y7pz6ss/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa
Successfully built fairscale antlr4-python3-runtime seqeval
Installing collected packages: tokenizers, sentencepiece, distlib, antlr4-python3-runtime, xxhash, virtualenv, ujson, tensorboardX, pyDeprecate, Pillow, ordered-set, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nptyping, networkx, multidict, lightning-utilities, jsonschema, jmespath, frozenlist, dill, deprecated, colorama, async-timeout, yarl, responses, pytesseract, nvidia-cudnn-cu11, multiprocess, model-index, huggingface-hub, botocore, aiosignal, transformers, torch, seqeval, s3transfer, ray, openmim, gluonts, catboost, aiohttp, torchvision, torchmetrics, statsforecast, sktime, pytorch-metric-learning, pmdarima, nlpaug, fairscale, boto3, accelerate, timm, tbats, pytorch-lightning, datasets, autogluon.common, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon
  Attempting uninstall: Pillow
    Found existing installation: Pillow 8.4.0
    Uninstalling Pillow-8.4.0:
      Successfully uninstalled Pillow-8.4.0
  Attempting uninstall: networkx
    Found existing installation: networkx 3.1
    Uninstalling networkx-3.1:
      Successfully uninstalled networkx-3.1
  Attempting uninstall: jsonschema
    Found existing installation: jsonschema 4.3.3
    Uninstalling jsonschema-4.3.3:
      Successfully uninstalled jsonschema-4.3.3
  Attempting uninstall: torch
    Found existing installation: torch 2.0.1+cu118
    Uninstalling torch-2.0.1+cu118:
      Successfully uninstalled torch-2.0.1+cu118
  Attempting uninstall: torchvision
    Found existing installation: torchvision 0.15.2+cu118
    Uninstalling torchvision-0.15.2+cu118:
      Successfully uninstalled torchvision-0.15.2+cu118
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
Successfully installed Pillow-9.5.0 accelerate-0.16.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 autogluon-0.7.0 autogluon.common-0.7.0 autogluon.core-0.7.0 autogluon.features-0.7.0 autogluon.multimodal-0.7.0 autogluon.tabular-0.7.0 autogluon.timeseries-0.7.0 boto3-1.26.151 botocore-1.29.151 catboost-1.1.1 colorama-0.4.6 datasets-2.12.0 deprecated-1.2.14 dill-0.3.6 distlib-0.3.6 evaluate-0.3.0 fairscale-0.4.13 frozenlist-1.3.3 gluonts-0.12.8 huggingface-hub-0.15.1 jmespath-1.0.1 jsonschema-4.17.3 lightning-utilities-0.8.0 model-index-0.1.11 multidict-6.0.4 multiprocess-0.70.14 networkx-2.8.8 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.2.3 openmim-0.3.7 ordered-set-4.1.0 pmdarima-1.8.5 pyDeprecate-0.3.2 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.2.0 responses-0.18.0 s3transfer-0.6.1 sentencepiece-0.1.99 seqeval-1.2.2 sktime-0.15.1 statsforecast-1.4.0 tbats-1.1.3 tensorboardX-2.6 timm-0.6.13 tokenizers-0.13.3 torch-1.13.1 torchmetrics-0.8.2 torchvision-0.14.1 transformers-4.26.1 ujson-5.7.0 virtualenv-20.23.0 xxhash-3.2.0 yarl-1.9.2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb9"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;pip_warning&quot;</span><span class="fu">:{</span><span class="dt">&quot;packages&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="st">&quot;PIL&quot;</span><span class="ot">,</span><span class="st">&quot;pydevd_plugins&quot;</span><span class="ot">]</span><span class="fu">}}</span></span></code></pre></div>
</div>
</div>
<div class="cell code" id="GRXLojhGm0JN">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<section id="setup-kaggle-api-key" class="cell markdown"
id="wvvIDIWLI2w9">
<h3>Setup Kaggle API Key</h3>
</section>
<div class="cell code" data-execution_count="3" id="bf--W4_QI2w9">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the .kaggle directory and an empty kaggle.json file</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>mkdir <span class="op">-</span>p <span class="op">/</span>root<span class="op">/</span>.kaggle</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>touch <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>chmod <span class="dv">600</span> <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="4" id="mXq3nbKfI2w-">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in your user name and key from creating the kaggle account and API token file</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>kaggle_username <span class="op">=</span> <span class="st">&quot;excellus&quot;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>kaggle_key <span class="op">=</span> <span class="st">&quot;a061493066408d19bcef9b0925e6ceda&quot;</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save API token the kaggle.json file</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;/root/.kaggle/kaggle.json&quot;</span>, <span class="st">&quot;w&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    f.write(json.dumps({<span class="st">&quot;username&quot;</span>: kaggle_username, <span class="st">&quot;key&quot;</span>: kaggle_key}))</span></code></pre></div>
</div>
<section id="download-and-explore-dataset" class="cell markdown"
id="eLYY8jW1I2w-">
<h3>Download and explore dataset</h3>
</section>
<section
id="go-to-the-bike-sharing-demand-competition-and-agree-to-the-terms"
class="cell markdown" id="BGUaWk46I2w_">
<h3>Go to the bike sharing demand competition and agree to the
terms</h3>
</section>
<div class="cell code" data-execution_count="5"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="QuK9k86YI2w_" data-outputId="0157fd1f-f68b-48e5-eb17-99ca961127ee">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset, it will be in a .zip file so you&#39;ll need to unzip it as well.</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions download <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># If you already downloaded it you can use the -o command to overwrite the file</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip <span class="op">-</span>o bike<span class="op">-</span>sharing<span class="op">-</span>demand.<span class="bu">zip</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading bike-sharing-demand.zip to /content
  0% 0.00/189k [00:00&lt;?, ?B/s]
100% 189k/189k [00:00&lt;00:00, 86.1MB/s]
Archive:  bike-sharing-demand.zip
  inflating: sampleSubmission.csv    
  inflating: test.csv                
  inflating: train.csv               
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="6" id="JM54Qq18I2w_">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularPredictor</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="7"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="J0R3gajfI2xA" data-outputId="32ff9ff4-08dc-49d5-ad28-87affbf0f9ed">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the train dataset in pandas by reading the csv</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the parsing of the datetime column so you can use some of the `dt` features in pandas later</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.read_csv(<span class="st">&#39;train.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="7">

  <div id="df-7e9b9e16-9cde-494e-a3fc-23b1c495383d">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7e9b9e16-9cde-494e-a3fc-23b1c495383d')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-7e9b9e16-9cde-494e-a3fc-23b1c495383d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-7e9b9e16-9cde-494e-a3fc-23b1c495383d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="8"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:344}"
id="jpqSJ4qvI2xA" data-outputId="171aada7-8308-4e6d-99ac-370fc2eb7462">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple output of the train dataset to view some of the min/max/varition of the dataset features.</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>train.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">

  <div id="df-dc54f871-5e35-44d4-8310-984738b9104d">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.00000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.506614</td>
      <td>0.028569</td>
      <td>0.680875</td>
      <td>1.418427</td>
      <td>20.23086</td>
      <td>23.655084</td>
      <td>61.886460</td>
      <td>12.799395</td>
      <td>36.021955</td>
      <td>155.552177</td>
      <td>191.574132</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.116174</td>
      <td>0.166599</td>
      <td>0.466159</td>
      <td>0.633839</td>
      <td>7.79159</td>
      <td>8.474601</td>
      <td>19.245033</td>
      <td>8.164537</td>
      <td>49.960477</td>
      <td>151.039033</td>
      <td>181.144454</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.82000</td>
      <td>0.760000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>13.94000</td>
      <td>16.665000</td>
      <td>47.000000</td>
      <td>7.001500</td>
      <td>4.000000</td>
      <td>36.000000</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>20.50000</td>
      <td>24.240000</td>
      <td>62.000000</td>
      <td>12.998000</td>
      <td>17.000000</td>
      <td>118.000000</td>
      <td>145.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>26.24000</td>
      <td>31.060000</td>
      <td>77.000000</td>
      <td>16.997900</td>
      <td>49.000000</td>
      <td>222.000000</td>
      <td>284.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>41.00000</td>
      <td>45.455000</td>
      <td>100.000000</td>
      <td>56.996900</td>
      <td>367.000000</td>
      <td>886.000000</td>
      <td>977.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-dc54f871-5e35-44d4-8310-984738b9104d')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-dc54f871-5e35-44d4-8310-984738b9104d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-dc54f871-5e35-44d4-8310-984738b9104d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="9"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="TINMv725I2xB" data-outputId="fb0031b9-a151-47a8-ce86-8454a3b4d1d7">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(<span class="st">&#39;test.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>test.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="9">

  <div id="df-a6362944-25bb-4ef5-b89f-e8971d52b41d">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>11.365</td>
      <td>56</td>
      <td>26.0027</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a6362944-25bb-4ef5-b89f-e8971d52b41d')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a6362944-25bb-4ef5-b89f-e8971d52b41d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a6362944-25bb-4ef5-b89f-e8971d52b41d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="10"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="uLXAR3VZI2xC" data-outputId="77329bc0-4c85-4ab1-bd49-f13594e0662c">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as train and test dataset</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>submission <span class="op">=</span> pd.read_csv(<span class="st">&#39;sampleSubmission.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>submission.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">

  <div id="df-945b46b6-eb39-474a-8c00-652d227ab9df">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-945b46b6-eb39-474a-8c00-652d227ab9df')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-945b46b6-eb39-474a-8c00-652d227ab9df button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-945b46b6-eb39-474a-8c00-652d227ab9df');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<section id="step-3-train-a-model-using-autogluons-tabular-prediction"
class="cell markdown" id="eK-AjHaAI2xD">
<h2>Step 3: Train a model using AutoGluon’s Tabular Prediction</h2>
</section>
<div class="cell markdown" id="FYof6pYzI2xE">
<p>Requirements:</p>
<ul>
<li>We are prediting <code>count</code>, so it is the label we are
setting.</li>
<li>Ignore <code>casual</code> and <code>registered</code> columns as
they are also not present in the test dataset.</li>
<li>Use the <code>root_mean_squared_error</code> as the metric to use
for evaluation.</li>
<li>Set a time limit of 10 minutes (600 seconds).</li>
<li>Use the preset <code>best_quality</code> to focus on creating the
best model.</li>
</ul>
</div>
<div class="cell code" data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="7GHii-JWI2xE" data-outputId="ea51b91b-a4bb-4c6c-9aa5-679d1ed08a0c">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autogluon.core.utils <span class="im">import</span> root_mean_squared_error</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>, eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, learner_kwargs<span class="op">=</span>{<span class="st">&#39;ignored_columns&#39;</span>: [<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>]}).fit(</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> train,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    time_limit <span class="op">=</span> <span class="dv">600</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230610_092850/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230610_092850/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 11
Label Column: count
Preprocessing data ...
AutoGluon infers your prediction problem is: &#39;regression&#39; (because dtype of label-column == int and many unique label-values observed).
	Label info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)
	If &#39;regression&#39; is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: [&#39;binary&#39;, &#39;multiclass&#39;, &#39;regression&#39;])
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    12235.83 MB
	Train Data (Original)  Memory Usage: 0.78 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 5 | [&#39;season&#39;, &#39;holiday&#39;, &#39;workingday&#39;, &#39;weather&#39;, &#39;humidity&#39;]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.2s = Fit runtime
	9 features in original data used to generate 13 features in processed data.
	Train Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.23s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.74s of the 599.76s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.04s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 393.98s of the 593.99s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.03s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 393.86s of the 593.88s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-131.4609	 = Validation score   (-root_mean_squared_error)
	106.14s	 = Training   runtime
	23.74s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 272.95s of the 472.96s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-131.0542	 = Validation score   (-root_mean_squared_error)
	41.5s	 = Training   runtime
	3.12s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 225.85s of the 425.87s of remaining time.
	-116.5484	 = Validation score   (-root_mean_squared_error)
	14.79s	 = Training   runtime
	0.77s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 208.76s of the 408.78s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-130.7735	 = Validation score   (-root_mean_squared_error)
	178.58s	 = Training   runtime
	0.21s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 23.21s of the 223.23s of remaining time.
	-124.6007	 = Validation score   (-root_mean_squared_error)
	10.03s	 = Training   runtime
	0.79s	 = Validation runtime
Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 11.0s of the 211.02s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-147.9577	 = Validation score   (-root_mean_squared_error)
	46.77s	 = Training   runtime
	0.42s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 159.17s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.55s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 158.59s of the 158.58s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-60.4588	 = Validation score   (-root_mean_squared_error)
	90.78s	 = Training   runtime
	7.76s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 62.32s of the 62.31s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-54.9677	 = Validation score   (-root_mean_squared_error)
	36.51s	 = Training   runtime
	0.36s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 21.53s of the 21.51s of remaining time.
	-53.3055	 = Validation score   (-root_mean_squared_error)
	43.74s	 = Training   runtime
	0.93s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -24.33s of remaining time.
	-53.0115	 = Validation score   (-root_mean_squared_error)
	0.31s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 624.68s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230610_092850/&quot;)
</code></pre>
</div>
</div>
<section
id="review-autogluons-training-run-with-ranking-of-models-that-did-the-best"
class="cell markdown" id="Hdpsk78SI2xF">
<h3>Review AutoGluon's training run with ranking of models that did the
best.</h3>
</section>
<div class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="WsZR0dRlI2xF" data-outputId="d332a559-dc7b-4f61-8d6e-be5fc22a2b42">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>predictor.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -53.011483      38.187880  569.233459                0.001251           0.313650            3       True         13
1   RandomForestMSE_BAG_L2  -53.305456      30.075262  441.629551                0.933483          43.737043            2       True         12
2          LightGBM_BAG_L2  -54.967706      29.497382  434.400963                0.355603          36.508456            2       True         11
3        LightGBMXT_BAG_L2  -60.458754      36.897542  488.674310                7.755763          90.781802            2       True         10
4    KNeighborsDist_BAG_L1  -84.125061       0.045122    0.032334                0.045122           0.032334            1       True          2
5      WeightedEnsemble_L2  -84.125061       0.046184    0.582237                0.001061           0.549902            2       True          9
6    KNeighborsUnif_BAG_L1 -101.546199       0.045673    0.042171                0.045673           0.042171            1       True          1
7   RandomForestMSE_BAG_L1 -116.548359       0.768010   14.793961                0.768010          14.793961            1       True          5
8     ExtraTreesMSE_BAG_L1 -124.600676       0.787081   10.030829                0.787081          10.030829            1       True          7
9          CatBoost_BAG_L1 -130.773536       0.211456  178.584554                0.211456         178.584554            1       True          6
10         LightGBM_BAG_L1 -131.054162       3.124785   41.500383                3.124785          41.500383            1       True          4
11       LightGBMXT_BAG_L1 -131.460909      23.740042  106.138750               23.740042         106.138750            1       True          3
12  NeuralNetFastAI_BAG_L1 -147.957711       0.419610   46.769526                0.419610          46.769526            1       True          8
Number of models trained: 13
Types of models trained:
{&#39;StackerEnsembleModel_CatBoost&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_XT&#39;, &#39;StackerEnsembleModel_NNFastAiTabular&#39;, &#39;StackerEnsembleModel_KNN&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="12">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;StackerEnsembleModel_NNFastAiTabular&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -131.46090891834504,
  &#39;LightGBM_BAG_L1&#39;: -131.054161598899,
  &#39;RandomForestMSE_BAG_L1&#39;: -116.54835939455667,
  &#39;CatBoost_BAG_L1&#39;: -130.7735359421953,
  &#39;ExtraTreesMSE_BAG_L1&#39;: -124.60067564699747,
  &#39;NeuralNetFastAI_BAG_L1&#39;: -147.95771124301584,
  &#39;WeightedEnsemble_L2&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L2&#39;: -60.45875384815452,
  &#39;LightGBM_BAG_L2&#39;: -54.96770638018026,
  &#39;RandomForestMSE_BAG_L2&#39;: -53.30545558837296,
  &#39;WeightedEnsemble_L3&#39;: -53.011482921969346},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_092850/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_092850/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_092850/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_092850/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_092850/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_092850/models/CatBoost_BAG_L1/&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_092850/models/ExtraTreesMSE_BAG_L1/&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_092850/models/NeuralNetFastAI_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230610_092850/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230610_092850/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230610_092850/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230610_092850/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230610_092850/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.04217052459716797,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.032334327697753906,
  &#39;LightGBMXT_BAG_L1&#39;: 106.13874959945679,
  &#39;LightGBM_BAG_L1&#39;: 41.50038266181946,
  &#39;RandomForestMSE_BAG_L1&#39;: 14.79396104812622,
  &#39;CatBoost_BAG_L1&#39;: 178.58455395698547,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 10.030829191207886,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 46.76952624320984,
  &#39;WeightedEnsemble_L2&#39;: 0.5499022006988525,
  &#39;LightGBMXT_BAG_L2&#39;: 90.7818021774292,
  &#39;LightGBM_BAG_L2&#39;: 36.508455753326416,
  &#39;RandomForestMSE_BAG_L2&#39;: 43.737043380737305,
  &#39;WeightedEnsemble_L3&#39;: 0.31364989280700684},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.04567289352416992,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.045122385025024414,
  &#39;LightGBMXT_BAG_L1&#39;: 23.740041971206665,
  &#39;LightGBM_BAG_L1&#39;: 3.1247854232788086,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.7680099010467529,
  &#39;CatBoost_BAG_L1&#39;: 0.2114555835723877,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 0.787081241607666,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 0.41960954666137695,
  &#39;WeightedEnsemble_L2&#39;: 0.0010614395141601562,
  &#39;LightGBMXT_BAG_L2&#39;: 7.755762815475464,
  &#39;LightGBM_BAG_L2&#39;: 0.3556032180786133,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.933483362197876,
  &#39;WeightedEnsemble_L3&#39;: 0.001251220703125},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;NeuralNetFastAI_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -53.011483      38.187880  569.233459   
 1   RandomForestMSE_BAG_L2  -53.305456      30.075262  441.629551   
 2          LightGBM_BAG_L2  -54.967706      29.497382  434.400963   
 3        LightGBMXT_BAG_L2  -60.458754      36.897542  488.674310   
 4    KNeighborsDist_BAG_L1  -84.125061       0.045122    0.032334   
 5      WeightedEnsemble_L2  -84.125061       0.046184    0.582237   
 6    KNeighborsUnif_BAG_L1 -101.546199       0.045673    0.042171   
 7   RandomForestMSE_BAG_L1 -116.548359       0.768010   14.793961   
 8     ExtraTreesMSE_BAG_L1 -124.600676       0.787081   10.030829   
 9          CatBoost_BAG_L1 -130.773536       0.211456  178.584554   
 10         LightGBM_BAG_L1 -131.054162       3.124785   41.500383   
 11       LightGBMXT_BAG_L1 -131.460909      23.740042  106.138750   
 12  NeuralNetFastAI_BAG_L1 -147.957711       0.419610   46.769526   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.001251           0.313650            3       True   
 1                 0.933483          43.737043            2       True   
 2                 0.355603          36.508456            2       True   
 3                 7.755763          90.781802            2       True   
 4                 0.045122           0.032334            1       True   
 5                 0.001061           0.549902            2       True   
 6                 0.045673           0.042171            1       True   
 7                 0.768010          14.793961            1       True   
 8                 0.787081          10.030829            1       True   
 9                 0.211456         178.584554            1       True   
 10                3.124785          41.500383            1       True   
 11               23.740042         106.138750            1       True   
 12                0.419610          46.769526            1       True   
 
     fit_order  
 0          13  
 1          12  
 2          11  
 3          10  
 4           2  
 5           9  
 6           1  
 7           5  
 8           7  
 9           6  
 10          4  
 11          3  
 12          8  }</code></pre>
</div>
</div>
<section id="create-predictions-from-test-dataset" class="cell markdown"
id="waYhLIwII2xF">
<h3>Create predictions from test dataset</h3>
</section>
<div class="cell code" data-execution_count="13"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="4VV6i0A8I2xF" data-outputId="1a1970f8-2c73-43ff-b378-fe8f5deb858f">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predictor.predict(test)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>predictions.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="13">
<pre><code>0    23.001648
1    42.759777
2    45.703575
3    48.479240
4    50.708763
Name: count, dtype: float32</code></pre>
</div>
</div>
<section
id="note-kaggle-will-reject-the-submission-if-we-dont-set-everything-to-be--0"
class="cell markdown" id="yxiGp1VEI2xG">
<h4>NOTE: Kaggle will reject the submission if we don't set everything
to be &gt; 0.</h4>
</section>
<div class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="2LriP6fVI2xG" data-outputId="61eab7cc-53ce-4c05-dbf8-3d9e860b2ce9">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Describe the `predictions` series to see if there are any negative values</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>predictions.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="14">
<pre><code>count    6493.000000
mean      100.503311
std        89.892845
min         3.336508
25%        19.710762
50%        63.463894
75%       167.184967
max       364.043427
Name: count, dtype: float64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="6gUls1PQI2xG" data-outputId="3fa7baed-3b19-4c47-f843-a6d2e0c68452">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many negative values do we have?</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>scout <span class="op">=</span> [i <span class="cf">for</span> i <span class="kw">in</span> predictions <span class="cf">if</span> i<span class="op">&lt;</span><span class="dv">0</span>]</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(scout))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>0
</code></pre>
</div>
</div>
<div class="cell code" id="xtPiA9hUI2xG">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set them to zero</span></span></code></pre></div>
</div>
<section id="set-predictions-to-submission-dataframe-save-and-submit"
class="cell markdown" id="RNXHazhsI2xH">
<h3>Set predictions to submission dataframe, save, and submit</h3>
</section>
<div class="cell code" data-execution_count="16" id="2FgNTSksI2xH">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>submission[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>submission.to_csv(<span class="st">&quot;submission.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="uDp2tylHI2xH" data-outputId="dffeca2c-65ee-405e-c5f2-22eb8073e765">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission.csv <span class="op">-</span>m <span class="st">&quot;first raw submission&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:03&lt;00:00, 56.4kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<section
id="view-submission-via-the-command-line-or-in-the-web-browser-under-the-competitions-page---my-submissions"
class="cell markdown" id="h2KC7f_SI2xH">
<h4>View submission via the command line or in the web browser under the
competition's page - <code>My Submissions</code></h4>
</section>
<div class="cell code" data-execution_count="18"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="KjgPGN71I2xH" data-outputId="8e25fd99-86f8-4429-fbff-786a82095788">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission.csv               2023-06-10 09:46:40  first raw submission               complete  1.80091      1.80091       
submission_new_hpo.csv       2023-06-09 08:43:22  new features with hyperparameters  complete  0.70391      0.70391       
submission_new_features.csv  2023-06-09 07:03:38  new features                       complete  0.61235      0.61235       
submission_new_features.csv  2023-06-09 06:32:32  new features                       error                                
</code></pre>
</div>
</div>
<section id="initial-score-of-18009" class="cell markdown"
id="yGW6brGFI2xI">
<h4>Initial score of <code>1.8009</code></h4>
</section>
<section
id="step-4-exploratory-data-analysis-and-creating-an-additional-feature"
class="cell markdown" id="wBZgLK93I2xI">
<h2>Step 4: Exploratory Data Analysis and Creating an additional
feature</h2>
<ul>
<li>Any additional feature will do, but a great suggestion would be to
separate out the datetime into hour, day, or month parts.</li>
</ul>
</section>
<div class="cell code" data-execution_count="22"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="O0X-qBEoI2xP" data-outputId="5e4d9989-fee5-4168-e71f-aecfaa84255e">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">15</span>), xrot <span class="op">=</span> <span class="dv">45</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="22">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;datetime&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;season&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;weather&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;casual&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;registered&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;]], dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_e16d80837d624de6aa849e4bc85575ad/ba78d1be14e2b1ad055c274ae247beeddfb6ca1c.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="23" id="u4ptVp90I2xP">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new feature</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> train.datetime.dt.hour</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> test.datetime.dt.hour</span></code></pre></div>
</div>
<section
id="make-category-types-for-these-so-models-know-they-are-not-just-numbers"
class="cell markdown" id="gZMgcrYpI2xP">
<h2>Make category types for these so models know they are not just
numbers</h2>
<ul>
<li>AutoGluon originally sees these as ints, but in reality they are int
representations of a category.</li>
<li>Setting the dtype to category will classify these as categories in
AutoGluon.</li>
</ul>
</section>
<div class="cell code" data-execution_count="24" id="H8q6KPkeI2xQ">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="yHHS7QKPI2xQ" data-outputId="cfee2ea8-e421-444b-a7dc-565e47a4016d">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View are new feature</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="26">

  <div id="df-80450d48-ad58-4c94-9734-4d3f09cb583e">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-80450d48-ad58-4c94-9734-4d3f09cb583e')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-80450d48-ad58-4c94-9734-4d3f09cb583e button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-80450d48-ad58-4c94-9734-4d3f09cb583e');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="48oR886tI2xQ" data-outputId="206cf89f-1d8b-470f-ffb3-8c2664732e5a">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View histogram of all features again now with the hour feature</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>train.hist(bins<span class="op">=</span><span class="dv">10</span>, figsize <span class="op">=</span> (<span class="dv">20</span>, <span class="dv">15</span>), xrot <span class="op">=</span> <span class="dv">45</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="27">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;datetime&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;casual&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;registered&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;hour&#39;}&gt;, &lt;Axes: &gt;]], dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_e16d80837d624de6aa849e4bc85575ad/035fdfe29eb6321a3763b5cbc179ab035578ea7e.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="29"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="dmH66exAuzuB" data-outputId="48d5cb19-e3e9-4646-d25e-43e55b0a5314">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>train.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 10886 entries, 0 to 10885
Data columns (total 13 columns):
 #   Column      Non-Null Count  Dtype         
---  ------      --------------  -----         
 0   datetime    10886 non-null  datetime64[ns]
 1   season      10886 non-null  category      
 2   holiday     10886 non-null  int64         
 3   workingday  10886 non-null  int64         
 4   weather     10886 non-null  category      
 5   temp        10886 non-null  float64       
 6   atemp       10886 non-null  float64       
 7   humidity    10886 non-null  int64         
 8   windspeed   10886 non-null  float64       
 9   casual      10886 non-null  int64         
 10  registered  10886 non-null  int64         
 11  count       10886 non-null  int64         
 12  hour        10886 non-null  int64         
dtypes: category(2), datetime64[ns](1), float64(3), int64(7)
memory usage: 957.3 KB
</code></pre>
</div>
</div>
<section
id="step-5-rerun-the-model-with-the-same-settings-as-before-just-with-more-features"
class="cell markdown" id="RQfRNyAOI2xR">
<h2>Step 5: Rerun the model with the same settings as before, just with
more features</h2>
</section>
<div class="cell code" data-execution_count="33"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="iOUhvdc3I2xR" data-outputId="a093d8fe-ac50-4bc9-d860-6a1fe59d5981">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>, eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, learner_kwargs<span class="op">=</span>{<span class="st">&#39;ignored_columns&#39;</span>: [<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>]}).fit(</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> train,</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    time_limit <span class="op">=</span> <span class="dv">600</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>  </span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230610_101633/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230610_101633/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 12
Label Column: count
Preprocessing data ...
AutoGluon infers your prediction problem is: &#39;regression&#39; (because dtype of label-column == int and many unique label-values observed).
	Label info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)
	If &#39;regression&#39; is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: [&#39;binary&#39;, &#39;multiclass&#39;, &#39;regression&#39;])
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    11334.3 MB
	Train Data (Original)  Memory Usage: 0.72 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 4 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;hour&#39;]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 2 | [&#39;humidity&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.3s = Fit runtime
	10 features in original data used to generate 14 features in processed data.
	Train Data (Processed) Memory Usage: 0.92 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.4s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.63s of the 599.59s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.08s	 = Training   runtime
	0.1s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.34s of the 599.3s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.06s	 = Training   runtime
	0.09s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.13s of the 599.09s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-34.4573	 = Validation score   (-root_mean_squared_error)
	150.19s	 = Training   runtime
	36.54s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 211.29s of the 411.25s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-33.9196	 = Validation score   (-root_mean_squared_error)
	88.73s	 = Training   runtime
	8.13s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 105.96s of the 305.92s of remaining time.
	-38.4543	 = Validation score   (-root_mean_squared_error)
	20.98s	 = Training   runtime
	1.03s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 82.24s of the 282.2s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-37.1098	 = Validation score   (-root_mean_squared_error)
	88.82s	 = Training   runtime
	0.31s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 156.17s of remaining time.
	-32.3423	 = Validation score   (-root_mean_squared_error)
	0.8s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 155.32s of the 155.3s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.2201	 = Validation score   (-root_mean_squared_error)
	49.76s	 = Training   runtime
	2.4s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 95.8s of the 95.79s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-30.6263	 = Validation score   (-root_mean_squared_error)
	41.57s	 = Training   runtime
	0.65s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 49.13s of the 49.11s of remaining time.
	-31.9234	 = Validation score   (-root_mean_squared_error)
	45.01s	 = Training   runtime
	0.7s	 = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 2.56s of the 2.54s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Time limit exceeded... Skipping CatBoost_BAG_L2.
2023-06-10 10:26:35,569	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -2.35s of remaining time.
	-30.383	 = Validation score   (-root_mean_squared_error)
	0.41s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 602.83s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230610_101633/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="34"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="yNBc-ksAI2xR" data-outputId="83be07ce-deda-45fa-d35f-ce752ca2fdae">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -30.382961      49.949903  485.604491                0.001238           0.408988            3       True         11
1          LightGBM_BAG_L2  -30.626273      46.844237  390.427336                0.649786          41.568107            2       True          9
2        LightGBMXT_BAG_L2  -31.220074      48.596939  398.622327                2.402488          49.763098            2       True          8
3   RandomForestMSE_BAG_L2  -31.923358      46.896392  393.864299                0.701941          45.005069            2       True         10
4      WeightedEnsemble_L2  -32.342318      46.097553  349.575978                0.001298           0.799520            2       True          7
5          LightGBM_BAG_L1  -33.919639       8.126745   88.733579                8.126745          88.733579            1       True          4
6        LightGBMXT_BAG_L1  -34.457274      36.535236  150.185348               36.535236         150.185348            1       True          3
7          CatBoost_BAG_L1  -37.109765       0.309762   88.820902                0.309762          88.820902            1       True          6
8   RandomForestMSE_BAG_L1  -38.454338       1.031846   20.977431                1.031846          20.977431            1       True          5
9    KNeighborsDist_BAG_L1  -84.125061       0.092666    0.059197                0.092666           0.059197            1       True          2
10   KNeighborsUnif_BAG_L1 -101.546199       0.098195    0.082772                0.098195           0.082772            1       True          1
Number of models trained: 11
Types of models trained:
{&#39;StackerEnsembleModel_CatBoost&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_KNN&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 2 | [&#39;humidity&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="34">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -34.457273921492806,
  &#39;LightGBM_BAG_L1&#39;: -33.919639163586254,
  &#39;RandomForestMSE_BAG_L1&#39;: -38.4543378929385,
  &#39;CatBoost_BAG_L1&#39;: -37.10976460664507,
  &#39;WeightedEnsemble_L2&#39;: -32.342318376234175,
  &#39;LightGBMXT_BAG_L2&#39;: -31.220073766321757,
  &#39;LightGBM_BAG_L2&#39;: -30.62627282690289,
  &#39;RandomForestMSE_BAG_L2&#39;: -31.923357650397417,
  &#39;WeightedEnsemble_L3&#39;: -30.382961234015774},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_101633/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_101633/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_101633/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_101633/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_101633/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230610_101633/models/CatBoost_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230610_101633/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230610_101633/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230610_101633/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230610_101633/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230610_101633/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.08277225494384766,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.059197187423706055,
  &#39;LightGBMXT_BAG_L1&#39;: 150.1853482723236,
  &#39;LightGBM_BAG_L1&#39;: 88.73357892036438,
  &#39;RandomForestMSE_BAG_L1&#39;: 20.977431058883667,
  &#39;CatBoost_BAG_L1&#39;: 88.82090163230896,
  &#39;WeightedEnsemble_L2&#39;: 0.7995204925537109,
  &#39;LightGBMXT_BAG_L2&#39;: 49.763097524642944,
  &#39;LightGBM_BAG_L2&#39;: 41.56810688972473,
  &#39;RandomForestMSE_BAG_L2&#39;: 45.00506949424744,
  &#39;WeightedEnsemble_L3&#39;: 0.40898776054382324},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.09819531440734863,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.0926661491394043,
  &#39;LightGBMXT_BAG_L1&#39;: 36.53523635864258,
  &#39;LightGBM_BAG_L1&#39;: 8.126745223999023,
  &#39;RandomForestMSE_BAG_L1&#39;: 1.0318455696105957,
  &#39;CatBoost_BAG_L1&#39;: 0.30976247787475586,
  &#39;WeightedEnsemble_L2&#39;: 0.0012977123260498047,
  &#39;LightGBMXT_BAG_L2&#39;: 2.4024877548217773,
  &#39;LightGBM_BAG_L2&#39;: 0.6497855186462402,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.7019405364990234,
  &#39;WeightedEnsemble_L3&#39;: 0.001237630844116211},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -30.382961      49.949903  485.604491   
 1          LightGBM_BAG_L2  -30.626273      46.844237  390.427336   
 2        LightGBMXT_BAG_L2  -31.220074      48.596939  398.622327   
 3   RandomForestMSE_BAG_L2  -31.923358      46.896392  393.864299   
 4      WeightedEnsemble_L2  -32.342318      46.097553  349.575978   
 5          LightGBM_BAG_L1  -33.919639       8.126745   88.733579   
 6        LightGBMXT_BAG_L1  -34.457274      36.535236  150.185348   
 7          CatBoost_BAG_L1  -37.109765       0.309762   88.820902   
 8   RandomForestMSE_BAG_L1  -38.454338       1.031846   20.977431   
 9    KNeighborsDist_BAG_L1  -84.125061       0.092666    0.059197   
 10   KNeighborsUnif_BAG_L1 -101.546199       0.098195    0.082772   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.001238           0.408988            3       True   
 1                 0.649786          41.568107            2       True   
 2                 2.402488          49.763098            2       True   
 3                 0.701941          45.005069            2       True   
 4                 0.001298           0.799520            2       True   
 5                 8.126745          88.733579            1       True   
 6                36.535236         150.185348            1       True   
 7                 0.309762          88.820902            1       True   
 8                 1.031846          20.977431            1       True   
 9                 0.092666           0.059197            1       True   
 10                0.098195           0.082772            1       True   
 
     fit_order  
 0          11  
 1           9  
 2           8  
 3          10  
 4           7  
 5           4  
 6           3  
 7           6  
 8           5  
 9           2  
 10          1  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="35" id="eJflAicexL21">
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>new_prediction <span class="op">=</span> predictor_new_features.predict(test)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="36"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="5q5n2B1PysHN" data-outputId="1fd691da-cf81-49d2-95d0-623896c096b5">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>new_prediction.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="36">
<pre><code>count    6493.000000
mean      161.098297
std       143.349518
min         2.109011
25%        49.199249
50%       121.562775
75%       231.306046
max       805.018005
Name: count, dtype: float64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="37" id="n9NGXPL7I2xS">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>new_predictions <span class="op">=</span> [<span class="dv">0</span> <span class="cf">if</span> i<span class="op">&lt;</span><span class="dv">0</span> <span class="cf">else</span> i <span class="cf">for</span> i <span class="kw">in</span> new_prediction]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="38" id="BzWfWtCfI2xS">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>submission_new_features <span class="op">=</span> pd.DataFrame()</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>submission_new_features[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> new_prediction</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>submission_new_features[<span class="st">&quot;datetime&quot;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>]</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>submission_new_features.to_csv(<span class="st">&quot;submission_new_features.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="39"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="WJgmIL-ZI2xS" data-outputId="92465adf-b963-4f93-8975-35315e812157">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_features.csv <span class="op">-</span>m <span class="st">&quot;new features&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:03&lt;00:00, 51.1kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="40"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="22OnMFnXI2xT" data-outputId="99fe6890-db41-486a-8064-e2079ca877e5">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_features.csv  2023-06-10 10:33:45  new features                       complete  0.63635      0.63635       
submission.csv               2023-06-10 09:46:40  first raw submission               complete  1.80091      1.80091       
submission_new_hpo.csv       2023-06-09 08:43:22  new features with hyperparameters  complete  0.70391      0.70391       
submission_new_features.csv  2023-06-09 07:03:38  new features                       complete  0.61235      0.61235       
</code></pre>
</div>
</div>
<section id="new-score-of-063" class="cell markdown" id="XKkMzBZOI2xT">
<h4>New Score of <code>0.63</code></h4>
</section>
<section id="step-6-hyper-parameter-optimization" class="cell markdown"
id="ZIA7PyHTI2xT">
<h2>Step 6: Hyper parameter optimization</h2>
<ul>
<li>There are many options for hyper parameter optimization.</li>
<li>Options are to change the AutoGluon higher level parameters or the
individual model hyperparameters.</li>
<li>The hyperparameters of the models themselves that are in AutoGluon.
Those need the <code>hyperparameter</code> and
<code>hyperparameter_tune_kwargs</code> arguments.</li>
</ul>
</section>
<div class="cell code" data-execution_count="41"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;43e0bd1761d14976ac8be52693bfb573&quot;,&quot;def96c7ccf134c438f8d40420ac0d167&quot;,&quot;d4515a6265b6410eaaf25b84499713eb&quot;,&quot;0252e8233d2a4c279cda2226bdb6edec&quot;,&quot;df5e01e3f61743ea9892b7bdbcfd19b2&quot;,&quot;885f93f3b7bf4fd2be0c494d460b113c&quot;,&quot;09c1f62155444fdb87084829ba75ae91&quot;,&quot;11670c9a81f649ca95be0f8d611edb57&quot;,&quot;e93070ca4ab3411897e34070b9f1eae6&quot;,&quot;c9b6737060a84bc3b381e7e152191d22&quot;,&quot;d6ed9f9923db45cfbfa4bf658e1aebcc&quot;,&quot;f939b7608edb4788a64755a80d1133d1&quot;,&quot;51c24069904044e09cf52b57dc953391&quot;,&quot;7b96db185fc443b7802db298de940867&quot;,&quot;537718e2a8d443bc99888a9d1605c63f&quot;,&quot;327118e2acc041958eba9412272a55ba&quot;,&quot;1e62b6677a354884879571a74108ac18&quot;,&quot;6613070bf7a1413aa73902d88a65482f&quot;,&quot;c7a5d64797b74acabe5d563add75306d&quot;,&quot;6ca39091e1164e458aca779a3d24e911&quot;,&quot;4621830f218247dcad6608196621c465&quot;,&quot;b9d8db122bcb4c44ae3dec71057e21d7&quot;,&quot;8e75dde0aab64ad8b41ddc6a97767c26&quot;,&quot;5a0b0fa8499e49c8b8794b170dc07796&quot;,&quot;9375b31ebad84f4fa9c60592670150a4&quot;,&quot;3c9b991bd16f4e3eb4d0251a3fa8e2ce&quot;,&quot;1c589c8f389f4d389b63f361a19b0980&quot;,&quot;0f1054d34c9d4b21865f52996f904d82&quot;,&quot;4240f464d11c4cd4bcb35839b50efd73&quot;,&quot;186d9ef5b7734ce097fb6b7ea4aa867b&quot;,&quot;027711cc8b634618885e137622232c51&quot;,&quot;8ea9d89c82ca44a8ba2fd0871b0d3469&quot;,&quot;b455a5e94aa34c928908a3628cc5228c&quot;]}"
id="AkxchH02I2xU" data-outputId="506443e7-2861-42f3-b191-a059fda9b7f6">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autogluon.core <span class="im">as</span> ag</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>nn_options <span class="op">=</span> {  <span class="co"># specifies non-default hyperparameter values for neural network models</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;num_epochs&#39;</span>: <span class="dv">10</span>,  <span class="co"># number of training epochs (controls training time of NN models)</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;learning_rate&#39;</span>: ag.space.Real(<span class="fl">1e-4</span>, <span class="fl">1e-2</span>, default<span class="op">=</span><span class="fl">5e-4</span>, log<span class="op">=</span><span class="va">True</span>),  <span class="co"># learning rate used in training (real-valued hyperparameter searched on log-scale)</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;layers&#39;</span>: ag.space.Categorical([<span class="dv">100</span>], [<span class="dv">1000</span>], [<span class="dv">200</span>, <span class="dv">100</span>], [<span class="dv">300</span>, <span class="dv">200</span>, <span class="dv">100</span>]), </span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;activation&#39;</span>: ag.space.Categorical(<span class="st">&#39;relu&#39;</span>, <span class="st">&#39;softrelu&#39;</span>, <span class="st">&#39;tanh&#39;</span>),  <span class="co"># activation function used in NN (categorical hyperparameter, default = first entry)</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;dropout_prob&#39;</span>: ag.space.Real(<span class="fl">0.0</span>, <span class="fl">0.5</span>, default<span class="op">=</span><span class="fl">0.1</span>),  <span class="co"># dropout probability (real-valued hyperparameter)</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>gbm_options <span class="op">=</span> {  <span class="co"># specifies non-default hyperparameter values for lightGBM gradient boosted trees</span></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;num_boost_round&#39;</span>: <span class="dv">100</span>,  <span class="co"># number of boosting rounds (controls training time of GBM models)</span></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;num_leaves&#39;</span>: ag.space.Int(lower<span class="op">=</span><span class="dv">26</span>, upper<span class="op">=</span><span class="dv">66</span>, default<span class="op">=</span><span class="dv">36</span>),  <span class="co"># number of leaves in trees (integer hyperparameter)</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>, eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, learner_kwargs<span class="op">=</span>{<span class="st">&#39;ignored_columns&#39;</span>: [<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>]}).fit(</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> train,</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>    time_limit <span class="op">=</span> <span class="dv">600</span>,</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>    presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>,</span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>    num_bag_folds <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>    num_bag_sets <span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>    num_stack_levels  <span class="op">=</span> <span class="dv">2</span>,</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>    hyperparameter_tune_kwargs <span class="op">=</span> {  <span class="co"># HPO is not performed unless hyperparameter_tune_kwargs is specified</span></span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;num_trials&#39;</span>: <span class="dv">5</span>,</span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;scheduler&#39;</span> : <span class="st">&#39;local&#39;</span>,</span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;searcher&#39;</span>: <span class="st">&#39;auto&#39;</span></span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a>    hyperparameters <span class="op">=</span> {  <span class="co"># hyperparameters of each model type</span></span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&#39;GBM&#39;</span>: gbm_options,</span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&#39;NN_TORCH&#39;</span>: nn_options,  <span class="co"># </span><span class="al">NOTE</span><span class="co">: comment this line out if you get errors on Mac OSX</span></span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a>                         }</span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230610_115333/&quot;
Presets specified: [&#39;best_quality&#39;]
Warning: hyperparameter tuning is currently experimental and may cause the process to hang.
Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=5, num_bag_sets=3
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230610_115333/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 12
Label Column: count
Preprocessing data ...
AutoGluon infers your prediction problem is: &#39;regression&#39; (because dtype of label-column == int and many unique label-values observed).
	Label info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)
	If &#39;regression&#39; is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: [&#39;binary&#39;, &#39;multiclass&#39;, &#39;regression&#39;])
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    11113.52 MB
	Train Data (Original)  Memory Usage: 0.72 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 4 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;hour&#39;]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 2 | [&#39;humidity&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.2s = Fit runtime
	10 features in original data used to generate 14 features in processed data.
	Train Data (Processed) Memory Usage: 0.92 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.3s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 3 stack levels (L1 to L3) ...
Fitting 2 L1 models ...
Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 119.91s of the 599.69s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb64"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;43e0bd1761d14976ac8be52693bfb573&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L1/T1 ...
	-40.304	 = Validation score   (-root_mean_squared_error)
	20.15s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T2 ...
	-39.2054	 = Validation score   (-root_mean_squared_error)
	22.96s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T3 ...
	-38.852	 = Validation score   (-root_mean_squared_error)
	22.54s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T4 ...
	-119.1839	 = Validation score   (-root_mean_squared_error)
	20.98s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T5 ...
	-43.3033	 = Validation score   (-root_mean_squared_error)
	21.85s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 119.91s of the 490.99s of remaining time.
Warning: Exception caused NeuralNetTorch_BAG_L1 to fail during hyperparameter tuning... Skipping this model.
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 252, in _lookup
    idx = categories.index(config_dict[key])
ValueError: [100] is not in list

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py&quot;, line 272, in fit
    return self._local_tuner.fit()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py&quot;, line 420, in fit
    analysis = self._fit_internal(trainable, param_space)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py&quot;, line 532, in _fit_internal
    analysis = run(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py&quot;, line 597, in run
    if config and not searcher_set_search_props(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/util.py&quot;, line 19, in _set_search_properties_backwards_compatible
    return set_search_properties_func(metric, mode, config, **spec)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/search_generator.py&quot;, line 63, in set_search_properties
    return _set_search_properties_backwards_compatible(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/util.py&quot;, line 19, in _set_search_properties_backwards_compatible
    return set_search_properties_func(metric, mode, config, **spec)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 292, in set_search_properties
    self._setup_hyperopt()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 222, in _setup_hyperopt
    self._convert_categories_to_indices(config)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 275, in _convert_categories_to_indices
    _lookup(config, self._space, k)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 271, in _lookup
    raise ValueError(msg) from exc
ValueError: Did not find category with value `[100]` in hyperopt parameter `layers`. Please make sure the specified category is valid.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py&quot;, line 1761, in _train_single_full
    hpo_models, hpo_results = model.hyperparameter_tune(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 1257, in hyperparameter_tune
    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 182, in _hyperparameter_tune
    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 1177, in _hyperparameter_tune
    hpo_executor.execute(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py&quot;, line 375, in execute
    analysis = run(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/ray_hpo.py&quot;, line 292, in run
    results = tuner.fit()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py&quot;, line 274, in fit
    raise TuneError(
ray.tune.error.TuneError: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(&quot;/content/AutogluonModels/ag-20230610_115333/models/NeuralNetTorch_BAG_L1&quot;)`.
The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(&quot;/content/AutogluonModels/ag-20230610_115333/models/NeuralNetTorch_BAG_L1&quot;)`.
Repeating k-fold bagging: 2/3
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 157.01s of the 490.24s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-39.951	 = Validation score   (-root_mean_squared_error)
	34.51s	 = Training   runtime
	0.19s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 134.95s of the 468.18s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-38.816	 = Validation score   (-root_mean_squared_error)
	38.73s	 = Training   runtime
	0.21s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 112.81s of the 446.04s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-38.3622	 = Validation score   (-root_mean_squared_error)
	40.76s	 = Training   runtime
	0.21s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T4 ... Training model for up to 90.01s of the 423.24s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-119.1608	 = Validation score   (-root_mean_squared_error)
	38.68s	 = Training   runtime
	0.64s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T5 ... Training model for up to 68.11s of the 401.34s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-42.9446	 = Validation score   (-root_mean_squared_error)
	39.69s	 = Training   runtime
	0.19s	 = Validation runtime
Completed 2/3 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 379.23s of remaining time.
	-38.0057	 = Validation score   (-root_mean_squared_error)
	0.3s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 2 L2 models ...
Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 113.64s of the 378.9s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb66"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f939b7608edb4788a64755a80d1133d1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L2/T1 ...
	-36.7453	 = Validation score   (-root_mean_squared_error)
	27.18s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T2 ...
	-36.7841	 = Validation score   (-root_mean_squared_error)
	22.76s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T3 ...
	-36.673	 = Validation score   (-root_mean_squared_error)
	22.13s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T4 ...
	-102.8289	 = Validation score   (-root_mean_squared_error)
	20.53s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ... Tuning model for up to 113.64s of the 286.12s of remaining time.
Warning: Exception caused NeuralNetTorch_BAG_L2 to fail during hyperparameter tuning... Skipping this model.
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 252, in _lookup
    idx = categories.index(config_dict[key])
ValueError: [100] is not in list

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py&quot;, line 272, in fit
    return self._local_tuner.fit()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py&quot;, line 420, in fit
    analysis = self._fit_internal(trainable, param_space)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py&quot;, line 532, in _fit_internal
    analysis = run(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py&quot;, line 597, in run
    if config and not searcher_set_search_props(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/util.py&quot;, line 19, in _set_search_properties_backwards_compatible
    return set_search_properties_func(metric, mode, config, **spec)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/search_generator.py&quot;, line 63, in set_search_properties
    return _set_search_properties_backwards_compatible(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/util.py&quot;, line 19, in _set_search_properties_backwards_compatible
    return set_search_properties_func(metric, mode, config, **spec)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 292, in set_search_properties
    self._setup_hyperopt()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 222, in _setup_hyperopt
    self._convert_categories_to_indices(config)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 275, in _convert_categories_to_indices
    _lookup(config, self._space, k)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 271, in _lookup
    raise ValueError(msg) from exc
ValueError: Did not find category with value `[100]` in hyperopt parameter `layers`. Please make sure the specified category is valid.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py&quot;, line 1761, in _train_single_full
    hpo_models, hpo_results = model.hyperparameter_tune(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 1257, in hyperparameter_tune
    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 182, in _hyperparameter_tune
    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 1177, in _hyperparameter_tune
    hpo_executor.execute(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py&quot;, line 375, in execute
    analysis = run(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/ray_hpo.py&quot;, line 292, in run
    results = tuner.fit()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py&quot;, line 274, in fit
    raise TuneError(
ray.tune.error.TuneError: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(&quot;/content/AutogluonModels/ag-20230610_115333/models/NeuralNetTorch_BAG_L2&quot;)`.
The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(&quot;/content/AutogluonModels/ag-20230610_115333/models/NeuralNetTorch_BAG_L2&quot;)`.
Repeating k-fold bagging: 2/3
Fitting model: LightGBM_BAG_L2/T1 ... Training model for up to 159.66s of the 286.02s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-36.5486	 = Validation score   (-root_mean_squared_error)
	41.9s	 = Training   runtime
	0.12s	 = Validation runtime
Fitting model: LightGBM_BAG_L2/T2 ... Training model for up to 138.81s of the 265.17s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-36.5276	 = Validation score   (-root_mean_squared_error)
	35.63s	 = Training   runtime
	0.11s	 = Validation runtime
Fitting model: LightGBM_BAG_L2/T3 ... Training model for up to 118.32s of the 244.67s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-36.477	 = Validation score   (-root_mean_squared_error)
	36.68s	 = Training   runtime
	0.2s	 = Validation runtime
Fitting model: LightGBM_BAG_L2/T4 ... Training model for up to 96.19s of the 222.53s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-102.8214	 = Validation score   (-root_mean_squared_error)
	35.18s	 = Training   runtime
	0.13s	 = Validation runtime
Completed 2/3 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 200.26s of remaining time.
	-36.3353	 = Validation score   (-root_mean_squared_error)
	0.26s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 2 L3 models ...
Hyperparameter tuning model: LightGBM_BAG_L3 ... Tuning model for up to 89.99s of the 199.96s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb68"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8e75dde0aab64ad8b41ddc6a97767c26&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L3/T1 ...
	-37.1752	 = Validation score   (-root_mean_squared_error)
	31.34s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L3/T2 ...
	-36.9652	 = Validation score   (-root_mean_squared_error)
	21.3s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L3/T3 ...
	-37.255	 = Validation score   (-root_mean_squared_error)
	22.6s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetTorch_BAG_L3 ... Tuning model for up to 89.99s of the 124.54s of remaining time.
Warning: Exception caused NeuralNetTorch_BAG_L3 to fail during hyperparameter tuning... Skipping this model.
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 252, in _lookup
    idx = categories.index(config_dict[key])
ValueError: [100] is not in list

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py&quot;, line 272, in fit
    return self._local_tuner.fit()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py&quot;, line 420, in fit
    analysis = self._fit_internal(trainable, param_space)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py&quot;, line 532, in _fit_internal
    analysis = run(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py&quot;, line 597, in run
    if config and not searcher_set_search_props(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/util.py&quot;, line 19, in _set_search_properties_backwards_compatible
    return set_search_properties_func(metric, mode, config, **spec)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/search_generator.py&quot;, line 63, in set_search_properties
    return _set_search_properties_backwards_compatible(
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/util.py&quot;, line 19, in _set_search_properties_backwards_compatible
    return set_search_properties_func(metric, mode, config, **spec)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 292, in set_search_properties
    self._setup_hyperopt()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 222, in _setup_hyperopt
    self._convert_categories_to_indices(config)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 275, in _convert_categories_to_indices
    _lookup(config, self._space, k)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/search/hyperopt/hyperopt_search.py&quot;, line 271, in _lookup
    raise ValueError(msg) from exc
ValueError: Did not find category with value `[100]` in hyperopt parameter `layers`. Please make sure the specified category is valid.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py&quot;, line 1761, in _train_single_full
    hpo_models, hpo_results = model.hyperparameter_tune(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 1257, in hyperparameter_tune
    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 182, in _hyperparameter_tune
    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 1177, in _hyperparameter_tune
    hpo_executor.execute(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py&quot;, line 375, in execute
    analysis = run(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/ray_hpo.py&quot;, line 292, in run
    results = tuner.fit()
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py&quot;, line 274, in fit
    raise TuneError(
ray.tune.error.TuneError: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(&quot;/content/AutogluonModels/ag-20230610_115333/models/NeuralNetTorch_BAG_L3&quot;)`.
The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(&quot;/content/AutogluonModels/ag-20230610_115333/models/NeuralNetTorch_BAG_L3&quot;)`.
Repeating k-fold bagging: 2/3
Fitting model: LightGBM_BAG_L3/T1 ... Training model for up to 124.45s of the 124.43s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-37.1391	 = Validation score   (-root_mean_squared_error)
	47.05s	 = Training   runtime
	0.15s	 = Validation runtime
Fitting model: LightGBM_BAG_L3/T2 ... Training model for up to 100.7s of the 100.68s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-36.9316	 = Validation score   (-root_mean_squared_error)
	35.38s	 = Training   runtime
	0.12s	 = Validation runtime
Fitting model: LightGBM_BAG_L3/T3 ... Training model for up to 78.3s of the 78.29s of remaining time.
	Fitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy
	-37.2995	 = Validation score   (-root_mean_squared_error)
	38.07s	 = Training   runtime
	0.26s	 = Validation runtime
Completed 2/3 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 54.4s of remaining time.
	-36.9174	 = Validation score   (-root_mean_squared_error)
	0.22s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 545.85s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230610_115333/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="42"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="lCh2RwhBI2xU" data-outputId="90399cac-5f47-4994-d096-575ee460d79f">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                  model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0   WeightedEnsemble_L3  -36.335292       1.742364  264.930813                0.000781           0.264498            3       True         11
1    LightGBM_BAG_L2/T3  -36.476981       1.636513  229.035243                0.197301          36.675584            2       True          9
2    LightGBM_BAG_L2/T2  -36.527589       1.544282  227.990730                0.105071          35.631072            2       True          8
3    LightGBM_BAG_L2/T1  -36.548553       1.560519  234.257274                0.121308          41.897616            2       True          7
4   WeightedEnsemble_L4  -36.917394       2.374095  415.410801                0.000716           0.218519            4       True         15
5    LightGBM_BAG_L3/T2  -36.931634       2.118157  377.122964                0.122768          35.375984            3       True         13
6    LightGBM_BAG_L3/T1  -37.139131       2.148363  388.796318                0.152974          47.049338            3       True         12
7    LightGBM_BAG_L3/T3  -37.299508       2.250611  379.816298                0.255222          38.069318            3       True         14
8   WeightedEnsemble_L2  -38.005692       0.415817   79.778728                0.000655           0.295336            2       True          6
9    LightGBM_BAG_L1/T3  -38.362243       0.207165   40.755682                0.207165          40.755682            1       True          3
10   LightGBM_BAG_L1/T2  -38.815990       0.207997   38.727710                0.207997          38.727710            1       True          2
11   LightGBM_BAG_L1/T1  -39.950980       0.190183   34.514558                0.190183          34.514558            1       True          1
12   LightGBM_BAG_L1/T5  -42.944612       0.191668   39.686077                0.191668          39.686077            1       True          5
13   LightGBM_BAG_L2/T4 -102.821419       1.571709  227.542708                0.132498          35.183050            2       True         10
14   LightGBM_BAG_L1/T4 -119.160803       0.642199   38.675632                0.642199          38.675632            1       True          4
Number of models trained: 15
Types of models trained:
{&#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_LGB&#39;}
Bagging used: True  (with 5 folds)
Multi-layer stack-ensembling used: True  (with 4 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 2 | [&#39;humidity&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="42">
<pre><code>{&#39;model_types&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T4&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T5&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T4&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L3/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L3/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L3/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L4&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: -39.95097956088215,
  &#39;LightGBM_BAG_L1/T2&#39;: -38.815990150971565,
  &#39;LightGBM_BAG_L1/T3&#39;: -38.36224279164567,
  &#39;LightGBM_BAG_L1/T4&#39;: -119.16080290168718,
  &#39;LightGBM_BAG_L1/T5&#39;: -42.944611934759024,
  &#39;WeightedEnsemble_L2&#39;: -38.00569191220602,
  &#39;LightGBM_BAG_L2/T1&#39;: -36.548553260826075,
  &#39;LightGBM_BAG_L2/T2&#39;: -36.5275886092826,
  &#39;LightGBM_BAG_L2/T3&#39;: -36.47698148968487,
  &#39;LightGBM_BAG_L2/T4&#39;: -102.82141869509974,
  &#39;WeightedEnsemble_L3&#39;: -36.33529181322099,
  &#39;LightGBM_BAG_L3/T1&#39;: -37.1391309276904,
  &#39;LightGBM_BAG_L3/T2&#39;: -36.93163369461465,
  &#39;LightGBM_BAG_L3/T3&#39;: -37.299507529876735,
  &#39;WeightedEnsemble_L4&#39;: -36.91739355483352},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L1/T1/&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L1/T2/&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L1/T3/&#39;,
  &#39;LightGBM_BAG_L1/T4&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L1/T4/&#39;,
  &#39;LightGBM_BAG_L1/T5&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L1/T5/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230610_115333/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L2/T1/&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L2/T2/&#39;,
  &#39;LightGBM_BAG_L2/T3&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L2/T3/&#39;,
  &#39;LightGBM_BAG_L2/T4&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L2/T4/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230610_115333/models/WeightedEnsemble_L3/&#39;,
  &#39;LightGBM_BAG_L3/T1&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L3/T1/&#39;,
  &#39;LightGBM_BAG_L3/T2&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L3/T2/&#39;,
  &#39;LightGBM_BAG_L3/T3&#39;: &#39;/content/AutogluonModels/ag-20230610_115333/models/LightGBM_BAG_L3/T3/&#39;,
  &#39;WeightedEnsemble_L4&#39;: &#39;AutogluonModels/ag-20230610_115333/models/WeightedEnsemble_L4/&#39;},
 &#39;model_fit_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 34.51455760002136,
  &#39;LightGBM_BAG_L1/T2&#39;: 38.727710247039795,
  &#39;LightGBM_BAG_L1/T3&#39;: 40.75568175315857,
  &#39;LightGBM_BAG_L1/T4&#39;: 38.67563199996948,
  &#39;LightGBM_BAG_L1/T5&#39;: 39.686076641082764,
  &#39;WeightedEnsemble_L2&#39;: 0.2953355312347412,
  &#39;LightGBM_BAG_L2/T1&#39;: 41.897616147994995,
  &#39;LightGBM_BAG_L2/T2&#39;: 35.63107204437256,
  &#39;LightGBM_BAG_L2/T3&#39;: 36.67558431625366,
  &#39;LightGBM_BAG_L2/T4&#39;: 35.18304967880249,
  &#39;WeightedEnsemble_L3&#39;: 0.2644984722137451,
  &#39;LightGBM_BAG_L3/T1&#39;: 47.04933762550354,
  &#39;LightGBM_BAG_L3/T2&#39;: 35.37598395347595,
  &#39;LightGBM_BAG_L3/T3&#39;: 38.06931805610657,
  &#39;WeightedEnsemble_L4&#39;: 0.21851873397827148},
 &#39;model_pred_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 0.19018292427062988,
  &#39;LightGBM_BAG_L1/T2&#39;: 0.20799708366394043,
  &#39;LightGBM_BAG_L1/T3&#39;: 0.20716500282287598,
  &#39;LightGBM_BAG_L1/T4&#39;: 0.6421985626220703,
  &#39;LightGBM_BAG_L1/T5&#39;: 0.19166779518127441,
  &#39;WeightedEnsemble_L2&#39;: 0.0006551742553710938,
  &#39;LightGBM_BAG_L2/T1&#39;: 0.1213080883026123,
  &#39;LightGBM_BAG_L2/T2&#39;: 0.10507059097290039,
  &#39;LightGBM_BAG_L2/T3&#39;: 0.19730138778686523,
  &#39;LightGBM_BAG_L2/T4&#39;: 0.13249754905700684,
  &#39;WeightedEnsemble_L3&#39;: 0.0007810592651367188,
  &#39;LightGBM_BAG_L3/T1&#39;: 0.15297365188598633,
  &#39;LightGBM_BAG_L3/T2&#39;: 0.12276840209960938,
  &#39;LightGBM_BAG_L3/T3&#39;: 0.2552220821380615,
  &#39;WeightedEnsemble_L4&#39;: 0.0007159709930419922},
 &#39;num_bag_folds&#39;: 5,
 &#39;max_stack_level&#39;: 4,
 &#39;model_hyperparams&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T4&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T5&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T4&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L3/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L3/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L3/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L4&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                   model   score_val  pred_time_val    fit_time  \
 0   WeightedEnsemble_L3  -36.335292       1.742364  264.930813   
 1    LightGBM_BAG_L2/T3  -36.476981       1.636513  229.035243   
 2    LightGBM_BAG_L2/T2  -36.527589       1.544282  227.990730   
 3    LightGBM_BAG_L2/T1  -36.548553       1.560519  234.257274   
 4   WeightedEnsemble_L4  -36.917394       2.374095  415.410801   
 5    LightGBM_BAG_L3/T2  -36.931634       2.118157  377.122964   
 6    LightGBM_BAG_L3/T1  -37.139131       2.148363  388.796318   
 7    LightGBM_BAG_L3/T3  -37.299508       2.250611  379.816298   
 8   WeightedEnsemble_L2  -38.005692       0.415817   79.778728   
 9    LightGBM_BAG_L1/T3  -38.362243       0.207165   40.755682   
 10   LightGBM_BAG_L1/T2  -38.815990       0.207997   38.727710   
 11   LightGBM_BAG_L1/T1  -39.950980       0.190183   34.514558   
 12   LightGBM_BAG_L1/T5  -42.944612       0.191668   39.686077   
 13   LightGBM_BAG_L2/T4 -102.821419       1.571709  227.542708   
 14   LightGBM_BAG_L1/T4 -119.160803       0.642199   38.675632   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000781           0.264498            3       True   
 1                 0.197301          36.675584            2       True   
 2                 0.105071          35.631072            2       True   
 3                 0.121308          41.897616            2       True   
 4                 0.000716           0.218519            4       True   
 5                 0.122768          35.375984            3       True   
 6                 0.152974          47.049338            3       True   
 7                 0.255222          38.069318            3       True   
 8                 0.000655           0.295336            2       True   
 9                 0.207165          40.755682            1       True   
 10                0.207997          38.727710            1       True   
 11                0.190183          34.514558            1       True   
 12                0.191668          39.686077            1       True   
 13                0.132498          35.183050            2       True   
 14                0.642199          38.675632            1       True   
 
     fit_order  
 0          11  
 1           9  
 2           8  
 3           7  
 4          15  
 5          13  
 6          12  
 7          14  
 8           6  
 9           3  
 10          2  
 11          1  
 12          5  
 13         10  
 14          4  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="43" id="BXgjlAmFI2xV">
<div class="sourceCode" id="cb74"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>predictor_new <span class="op">=</span> predictor_new_hpo.predict(test)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="44"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ClnPFflCTfuL" data-outputId="99b07e24-7fcd-4830-c212-765121c6f3bc">
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>predictor_new.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="44">
<pre><code>count    6493.000000
mean      192.202911
std       174.198761
min         5.340409
25%        45.942215
50%       149.797333
75%       288.514526
max       861.549622
Name: count, dtype: float64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="45"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pKHKabaFUEdZ" data-outputId="43f1918a-b871-4616-cc6f-748a6a153869">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>new_predictions_hpo <span class="op">=</span> [<span class="bu">round</span>(i) <span class="cf">for</span> i <span class="kw">in</span> predictor_new]</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>new_predictions_hpo[:<span class="dv">5</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="45">
<pre><code>[10, 6, 6, 6, 6]</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="46" id="XzusJfMEI2xV">
<div class="sourceCode" id="cb79"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>submission_new_hpo <span class="op">=</span> pd.DataFrame()</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>submission_new_hpo[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> new_predictions_hpo</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>submission_new_hpo[<span class="st">&quot;datetime&quot;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>]</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>submission_new_hpo.to_csv(<span class="st">&quot;submission_new_hpo.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="47"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="GHJdhNUGI2xW" data-outputId="240470de-a5ac-4f71-cc81-79ebb2841258">
<div class="sourceCode" id="cb80"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_hpo.csv <span class="op">-</span>m <span class="st">&quot;new features with hyperparameters&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 149k/149k [00:02&lt;00:00, 54.9kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="48"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="0SfwsqKuI2xW" data-outputId="06ed1749-9c15-4572-bc0f-950cc88de687">
<div class="sourceCode" id="cb82"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_hpo.csv       2023-06-10 12:03:41  new features with hyperparameters  complete  0.48044      0.48044       
submission_new_features.csv  2023-06-10 10:33:45  new features                       complete  0.63635      0.63635       
submission.csv               2023-06-10 09:46:40  first raw submission               complete  1.80091      1.80091       
submission_new_hpo.csv       2023-06-09 08:43:22  new features with hyperparameters  complete  0.70391      0.70391       
</code></pre>
</div>
</div>
<section id="new-score-of-04804" class="cell markdown"
id="eDuDB7omI2xX">
<h4>New Score of <code>0.4804</code></h4>
</section>
<section id="step-7-write-a-report" class="cell markdown"
id="qbglGASVI2xX">
<h2>Step 7: Write a Report</h2>
<h3 id="refer-to-the-markdown-file-for-the-full-report">Refer to the
markdown file for the full report</h3>
<h3 id="creating-plots-and-table-for-report">Creating plots and table
for report</h3>
</section>
<div class="cell code" data-execution_count="49"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}"
id="5h0Bkz7xI2xY" data-jupyter="{&quot;source_hidden&quot;:true}"
data-outputId="bf3b0775-e18f-4ed2-ef43-82b096a856f0">
<div class="sourceCode" id="cb84"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking the top model score from each training run and creating a line plot to show improvement</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="co"># You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)</span></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="op">-</span><span class="fl">53.01</span>, <span class="op">-</span><span class="fl">30.38</span>, <span class="op">-</span><span class="fl">36.33</span>]</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_train_scorenn.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_e16d80837d624de6aa849e4bc85575ad/b4fa662050aaf463ebc825fde3a715fc106cff53.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="50"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}"
id="2mhm2a9cI2xY" data-outputId="e6820939-ceae-4494-e6f5-f24ca506e797">
<div class="sourceCode" id="cb85"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Take the 3 kaggle scores and creating a line plot to show improvement</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;test_eval&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">1.80</span>, <span class="fl">0.63</span>, <span class="fl">0.48</span>]</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;test_eval&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_test_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_e16d80837d624de6aa849e4bc85575ad/efddccee5c8f5a9cd84adb09ef6e467e4877a30d.png" /></p>
</div>
</div>
<section id="hyperparameter-table" class="cell markdown"
id="0eEQzldvI2xY">
<h3>Hyperparameter table</h3>
</section>
<div class="cell code" data-execution_count="53"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:143}"
id="FGrxRp89I2xZ" data-outputId="e0560aa6-ada3-4739-d5de-181d49c09907">
<div class="sourceCode" id="cb86"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The 3 hyperparameters we tuned with the kaggle score as the result</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo1&quot;</span>: [<span class="st">&#39;def_val&#39;</span>, <span class="st">&#39;def_val&#39;</span>, <span class="st">&#39;NN&#39;</span>],</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo2&quot;</span>: [<span class="st">&#39;def_val&#39;</span>, <span class="st">&#39;def_val&#39;</span>, <span class="st">&#39;GBM&#39;</span>],</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo3&quot;</span>: [<span class="st">&#39;def_val&#39;</span>, <span class="st">&#39;def_val&#39;</span>, <span class="st">&#39;def_val&#39;</span>],</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;score&quot;</span>: [<span class="fl">1.80</span>, <span class="fl">0.63</span>, <span class="fl">0.48</span>]</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<div class="output execute_result" data-execution_count="53">

  <div id="df-9f0f9694-bff6-4371-81e5-b3dea468d1f2">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>hpo1</th>
      <th>hpo2</th>
      <th>hpo3</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>initial</td>
      <td>def_val</td>
      <td>def_val</td>
      <td>def_val</td>
      <td>1.80</td>
    </tr>
    <tr>
      <th>1</th>
      <td>add_features</td>
      <td>def_val</td>
      <td>def_val</td>
      <td>def_val</td>
      <td>0.63</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hpo</td>
      <td>NN</td>
      <td>GBM</td>
      <td>def_val</td>
      <td>0.48</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-9f0f9694-bff6-4371-81e5-b3dea468d1f2')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-9f0f9694-bff6-4371-81e5-b3dea468d1f2 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-9f0f9694-bff6-4371-81e5-b3dea468d1f2');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
</body>
</html>
